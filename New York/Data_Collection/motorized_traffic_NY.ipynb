{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937fb021-9b78-440a-887b-87d7e9f90210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from geopandas.tools import sjoin\n",
    "from shapely.geometry import Point\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0fbb4-5255-4e79-9d5f-382513bf3ca4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading and Preparing the Traffic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467ae29b-3403-4f38-8a51-679fec1ef111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the main traffic dataset\n",
    "traffic_df = pd.read_csv(\"Automated_Traffic_Volume_Counts_20250404.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aed2eeb-4b5e-422c-9a83-21bcca2c0a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1712605 entries, 0 to 1712604\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   RequestID  int64 \n",
      " 1   Boro       object\n",
      " 2   Yr         int64 \n",
      " 3   M          int64 \n",
      " 4   D          int64 \n",
      " 5   HH         int64 \n",
      " 6   MM         int64 \n",
      " 7   Vol        int64 \n",
      " 8   SegmentID  int64 \n",
      " 9   WktGeom    object\n",
      " 10  street     object\n",
      " 11  fromSt     object\n",
      " 12  toSt       object\n",
      " 13  Direction  object\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 182.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's check the info about the dataset\n",
    "traffic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f353738-1ed5-4bbc-ba97-307877207fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RequestID      Boro    Yr   M   D  HH  MM  Vol  SegmentID  \\\n",
      "0      32970    Queens  2021   4  30   2   0    0     149701   \n",
      "1      32970    Queens  2021   4  30   2  15    1     149701   \n",
      "2      11342  Brooklyn  2012  12  18   8  15   33      20063   \n",
      "3      32970    Queens  2021   4  30   2  30    0     149701   \n",
      "4      32970    Queens  2021   4  30   2  45    0     149701   \n",
      "\n",
      "                                        WktGeom          street  \\\n",
      "0  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "1  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "2                     POINT (985746.5 167127.4)           61 ST   \n",
      "3  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "4  POINT (997407.0998491726 208620.92612708386)  PULASKI BRIDGE   \n",
      "\n",
      "                    fromSt      toSt Direction  \n",
      "0  Newtown Creek Shoreline  Dead end        NB  \n",
      "1  Newtown Creek Shoreline  Dead end        NB  \n",
      "2                    15 AV     16 AV        WB  \n",
      "3  Newtown Creek Shoreline  Dead end        NB  \n",
      "4  Newtown Creek Shoreline  Dead end        NB  \n"
     ]
    }
   ],
   "source": [
    "# And, check the head of the dataset\n",
    "print(traffic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98f6a1c-c766-4d3b-8fe9-bf5bd0a1af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's convert columns to appropriate types\n",
    "traffic_df['Yr'] = traffic_df['Yr'].astype(int)\n",
    "traffic_df['M'] = traffic_df['M'].astype(int)\n",
    "traffic_df['D'] = traffic_df['D'].astype(int)\n",
    "traffic_df['HH'] = traffic_df['HH'].astype(int)\n",
    "traffic_df['MM'] = traffic_df['MM'].astype(int)\n",
    "traffic_df['Vol'] = pd.to_numeric(traffic_df['Vol'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Let's combine Yr, M, D into a proper datetime object and create a date column\n",
    "traffic_df['date'] = pd.to_datetime({\n",
    "    'year': traffic_df['Yr'],\n",
    "    'month': traffic_df['M'],\n",
    "    'day': traffic_df['D']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153ffe62-cee9-40a1-a120-2d118c54c20b",
   "metadata": {},
   "source": [
    "### Hourly to Daily Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2435f099-dc34-41f8-afaa-03c798d9b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SegmentID       date    Vol                                       WktGeom  \\\n",
      "0         44 2015-02-07  45506  POINT (914734.9916698899 120903.10647429322)   \n",
      "1         44 2015-02-08  44512  POINT (914734.9916698899 120903.10647429322)   \n",
      "2         44 2015-02-09  50696  POINT (914734.9916698899 120903.10647429322)   \n",
      "3         44 2015-02-10  34657  POINT (914734.9916698899 120903.10647429322)   \n",
      "4         44 2015-02-11  31097  POINT (914734.9916698899 120903.10647429322)   \n",
      "\n",
      "            Boro       street Direction  \n",
      "0  Staten Island  MOON AVENUE        SB  \n",
      "1  Staten Island  MOON AVENUE        SB  \n",
      "2  Staten Island  MOON AVENUE        NB  \n",
      "3  Staten Island  MOON AVENUE        NB  \n",
      "4  Staten Island  MOON AVENUE        SB  \n"
     ]
    }
   ],
   "source": [
    "# Let's aggregate volume to daily totals per segment\n",
    "daily_traffic = traffic_df.groupby(['SegmentID', 'date']).agg({\n",
    "    'Vol': 'sum',\n",
    "    'WktGeom': 'first',\n",
    "    'Boro': 'first',\n",
    "    'street': 'first',\n",
    "    'Direction': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# And, check the aggregated data\n",
    "print(daily_traffic.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025876e1-94f1-4fec-8abb-c7850feb1631",
   "metadata": {},
   "source": [
    "### Geospatial Processing of the Traffic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3301b132-abee-4188-bc41-72f49b723958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SegmentID       date    Vol                                       WktGeom  \\\n",
      "0         44 2015-02-07  45506  POINT (914734.9916698899 120903.10647429322)   \n",
      "1         44 2015-02-08  44512  POINT (914734.9916698899 120903.10647429322)   \n",
      "2         44 2015-02-09  50696  POINT (914734.9916698899 120903.10647429322)   \n",
      "3         44 2015-02-10  34657  POINT (914734.9916698899 120903.10647429322)   \n",
      "4         44 2015-02-11  31097  POINT (914734.9916698899 120903.10647429322)   \n",
      "\n",
      "            Boro       street Direction                    geometry  \n",
      "0  Staten Island  MOON AVENUE        SB  POINT (-74.24995 40.49825)  \n",
      "1  Staten Island  MOON AVENUE        SB  POINT (-74.24995 40.49825)  \n",
      "2  Staten Island  MOON AVENUE        NB  POINT (-74.24995 40.49825)  \n",
      "3  Staten Island  MOON AVENUE        NB  POINT (-74.24995 40.49825)  \n",
      "4  Staten Island  MOON AVENUE        SB  POINT (-74.24995 40.49825)  \n"
     ]
    }
   ],
   "source": [
    "# Let's convert WKTGeom to GeoDataFrame\n",
    "daily_traffic['geometry'] = daily_traffic['WktGeom'].apply(wkt.loads)\n",
    "\n",
    "# And, create GeoDataFrame (initial CRS: EPSG:2263, NY State Plane feet)\n",
    "traffic_gdf = gpd.GeoDataFrame(daily_traffic, geometry='geometry', crs='EPSG:2263')\n",
    "\n",
    "# And, convert to standard latitude/longitude CRS (EPSG:4326)\n",
    "traffic_gdf = traffic_gdf.to_crs('EPSG:4326')\n",
    "\n",
    "# And, also check the conversion\n",
    "print(traffic_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc575e7b-2350-4b46-ba5b-4ceb82da3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's drop unnecessary columns\n",
    "traffic_gdf = traffic_gdf.drop(columns=['WktGeom'])\n",
    "\n",
    "# And, save cleaned GeoDataFrame to file for spatial analysis\n",
    "traffic_gdf.to_file('daily_traffic_newyork.geojson', driver='GeoJSON')\n",
    "\n",
    "# Also save as CSV if needed\n",
    "traffic_gdf.to_csv('daily_traffic_newyork.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0286433-a724-4c77-929d-ea0195fec6cc",
   "metadata": {},
   "source": [
    "## Spatial Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416562ac-c079-48dd-85c1-29820a8f4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the bike data\n",
    "bike_df = pd.read_csv('daily_cycling_data_newyork_07042025.csv')\n",
    "\n",
    "# And, also the motor traffic data\n",
    "motor_df = pd.read_csv('daily_traffic_newyork.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187f20b7-594d-4ca4-a4a2-c02605d14ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime format and extract year\n",
    "bike_df['date'] = pd.to_datetime(bike_df['date'])\n",
    "motor_df['date'] = pd.to_datetime(motor_df['date'])\n",
    "motor_df['year'] = motor_df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c50bb3-d156-426c-8161-940eba2f1a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique dates in bike data: 3653\n",
      "Number of unique dates in motor data: 4928\n",
      "Number of common dates between bike and motor data: 2581\n",
      "Number of bike data dates missing in motor data: 1072\n",
      "Sample of missing dates: [datetime.date(2024, 4, 21), datetime.date(2020, 3, 26), datetime.date(2024, 4, 24), datetime.date(2018, 12, 29), datetime.date(2023, 12, 13), datetime.date(2021, 7, 23), datetime.date(2022, 1, 19), datetime.date(2022, 4, 19), datetime.date(2024, 9, 20), datetime.date(2020, 1, 3)]\n"
     ]
    }
   ],
   "source": [
    "# Unique dates in bike data\n",
    "bike_dates = pd.to_datetime(bike_df['date']).dt.date.unique()\n",
    "print(\"Number of unique dates in bike data:\", len(bike_dates))\n",
    "\n",
    "# Unique dates in motor data\n",
    "motor_dates = pd.to_datetime(motor_df['date']).dt.date.unique()\n",
    "print(\"Number of unique dates in motor data:\", len(motor_dates))\n",
    "\n",
    "# Find the intersection of dates\n",
    "common_dates = set(bike_dates).intersection(set(motor_dates))\n",
    "print(\"Number of common dates between bike and motor data:\", len(common_dates))\n",
    "\n",
    "# Dates missing in motor data\n",
    "missing_dates = set(bike_dates) - set(motor_dates)\n",
    "print(\"Number of bike data dates missing in motor data:\", len(missing_dates))\n",
    "\n",
    "# Print a few missing dates as a sample\n",
    "print(\"Sample of missing dates:\", list(missing_dates)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93eba2c-087a-4010-bd1b-0b6283513135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's create GeoDataFrames for bike data using EPSG:4326 and transforming to EPSG:2263\n",
    "bike_gdf = gpd.GeoDataFrame(\n",
    "    bike_df,\n",
    "    geometry=gpd.points_from_xy(bike_df.longitude, bike_df.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(epsg=2263)\n",
    "\n",
    "# And also, create GeoDataFrames for motor data using EPSG:4326 and transforming to EPSG:2263\n",
    "motor_gdf = gpd.GeoDataFrame(\n",
    "    motor_df,\n",
    "    geometry=gpd.points_from_xy(motor_df['geometry'].apply(lambda x: float(x.split(' ')[1].strip('()'))),\n",
    "                               motor_df['geometry'].apply(lambda x: float(x.split(' ')[2].strip('()')))),\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(epsg=2263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29123b0c-45d4-45fb-81b2-2806b97456c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the daily bike and motor traffic data\n",
    "bike_df = pd.read_csv('daily_cycling_data_newyork_03042025.csv')\n",
    "motor_gdf = gpd.read_file('daily_traffic_newyork.geojson')\n",
    "\n",
    "# And, convert dates to datetime\n",
    "bike_df['date'] = pd.to_datetime(bike_df['date'])\n",
    "motor_gdf['date'] = pd.to_datetime(motor_gdf['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c034442-7404-4191-9511-2b7b47b7e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's convert bike data to GeoDataFrame\n",
    "bike_gdf = gpd.GeoDataFrame(\n",
    "    bike_df,\n",
    "    geometry=gpd.points_from_xy(bike_df.longitude, bike_df.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ").to_crs(epsg=32618)\n",
    "\n",
    "# And, also the motorized traffic data from the GeoJSON\n",
    "motor_gdf = motor_gdf.to_crs(epsg=32618)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a41dff-3283-462d-a57d-a471c09cea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take out the unique dates from bicycle data\n",
    "unique_dates = bike_gdf['date'].dt.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4b93ad8-0649-4428-bc0b-54850ef12c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3653/3653 [04:15<00:00, 14.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare an empty results list\n",
    "results = []\n",
    "\n",
    "# Iterate through each unique date\n",
    "for current_date in tqdm(unique_dates):\n",
    "    # Filter daily bike and motor data\n",
    "    bike_day = bike_gdf[bike_gdf['date'].dt.date == current_date].copy()\n",
    "    motor_day = motor_gdf[motor_gdf['date'].dt.date == current_date].copy()\n",
    "\n",
    "    # Skip if either dataset is empty for the current date\n",
    "    if motor_day.empty or bike_day.empty:\n",
    "        continue\n",
    "\n",
    "    # Calculate city-wide average motorized volume for the day\n",
    "    city_avg_motor_volume = motor_day['Vol'].mean()\n",
    "    city_total_motor_vehicles = motor_day['Vol'].sum()\n",
    "\n",
    "    # Loop through each bike counter on that day\n",
    "    for idx, bike_row in bike_day.iterrows():\n",
    "        # Create a 6 km buffer around the bike station\n",
    "        buffer_geom = bike_row.geometry.buffer(6000)\n",
    "        \n",
    "        # Filter motorized traffic data within the buffer\n",
    "        nearby_motor = motor_day[motor_day.within(buffer_geom)]\n",
    "\n",
    "        # Skip if no motorized data is found within the buffer\n",
    "        if nearby_motor.empty:\n",
    "            continue\n",
    "\n",
    "        # Aggregate nearby motor features\n",
    "        avg_motor_volume = nearby_motor['Vol'].mean()\n",
    "        total_motor_vehicles = nearby_motor['Vol'].sum()\n",
    "        num_motor_sources = len(nearby_motor)\n",
    "\n",
    "        # Append the result\n",
    "        results.append({\n",
    "            'date': current_date,\n",
    "            'station_name': bike_row['name'],\n",
    "            'latitude': bike_row['latitude'],\n",
    "            'longitude': bike_row['longitude'],\n",
    "            'bike_counts': bike_row['counts'],\n",
    "            \n",
    "            # Local (6 km radius) motor features\n",
    "            'avg_motor_volume': avg_motor_volume,\n",
    "            'total_motor_vehicles': total_motor_vehicles,\n",
    "            'num_motor_sources': num_motor_sources,\n",
    "\n",
    "            # City-wide motor features\n",
    "            'city_avg_motor_volume': city_avg_motor_volume,\n",
    "            'city_total_motor_vehicles': city_total_motor_vehicles\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "389c311b-d47a-41f3-afff-40b07d4ffa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial aggregation completed and saved as 'ny_bike_with_motor_traffic.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the merged data\n",
    "final_df.to_csv('ny_bike_with_motor_traffic.csv', index=False)\n",
    "print(\"Spatial aggregation completed and saved as 'ny_bike_with_motor_traffic.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b943f816-9aa4-454a-8da4-402edc9be959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7750 entries, 0 to 7749\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   date                       7750 non-null   object \n",
      " 1   station_name               7750 non-null   object \n",
      " 2   latitude                   7750 non-null   float64\n",
      " 3   longitude                  7750 non-null   float64\n",
      " 4   bike_counts                7750 non-null   int64  \n",
      " 5   avg_motor_volume           7750 non-null   float64\n",
      " 6   total_motor_vehicles       7750 non-null   int64  \n",
      " 7   num_motor_sources          7750 non-null   int64  \n",
      " 8   city_avg_motor_volume      7750 non-null   float64\n",
      " 9   city_total_motor_vehicles  7750 non-null   int64  \n",
      "dtypes: float64(4), int64(4), object(2)\n",
      "memory usage: 605.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's quickly check the merged file\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bbbea7f-abee-46b7-a0dc-5b87f0f80c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Days for Each Year:\n",
      "   year  unique_days\n",
      "0  2015          177\n",
      "1  2016          215\n",
      "2  2017          217\n",
      "3  2018          166\n",
      "4  2019          222\n",
      "5  2020           99\n",
      "6  2021          163\n",
      "7  2022          150\n",
      "8  2023          197\n",
      "9  2024           97\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'date' column is in datetime format\n",
    "final_df['date'] = pd.to_datetime(final_df['date'])\n",
    "\n",
    "# Extract the year from the date column\n",
    "final_df['year'] = final_df['date'].dt.year\n",
    "\n",
    "# Group by year and count unique dates\n",
    "unique_days_per_year = final_df.groupby('year')['date'].nunique().reset_index()\n",
    "unique_days_per_year.rename(columns={'date': 'unique_days'}, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"Number of Unique Days for Each Year:\")\n",
    "print(unique_days_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f8e00-1b1b-4014-abfd-fc8bd7a2371b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513653b2-f71b-4535-8af1-bbfb4e39a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing station matches: 100%|██████████████████████████████████████████████| 36461/36461 [18:14<00:00, 33.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set the buffer size to 6 km (6000 meters)\n",
    "buffer_size = 6000\n",
    "\n",
    "# Precompute yearly median volume per segment\n",
    "yearly_median_vol = motor_gdf.groupby(['SegmentID', 'year'])['Vol'].median().reset_index()\n",
    "\n",
    "# Precompute station matches: find motor stations within 6 km of each bike station\n",
    "station_matches = {}\n",
    "for idx, bike_row in tqdm(bike_gdf.iterrows(), total=bike_gdf.shape[0], desc=\"Precomputing station matches\"):\n",
    "    buffer_geom = bike_row.geometry.buffer(buffer_size)\n",
    "    nearby_motor = motor_gdf[motor_gdf.geometry.within(buffer_geom)]\n",
    "    station_matches[bike_row['name']] = nearby_motor['SegmentID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2b8644-f7b5-45b6-ad8a-11680997f09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing each date: 100%|████████████████████████████████████████████████████████| 3653/3653 [06:54<00:00,  8.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "# Process each date\n",
    "for current_date in tqdm(bike_gdf['date'].dt.date.unique(), desc=\"Processing each date\"):\n",
    "    # Extract the current year\n",
    "    current_year = pd.to_datetime(current_date).year\n",
    "    \n",
    "    # Filter bike and motor data for the current date\n",
    "    bike_day = bike_gdf[bike_gdf['date'].dt.date == current_date].copy()\n",
    "    motor_day = motor_gdf[motor_gdf['date'].dt.date == current_date].copy()\n",
    "\n",
    "    # Calculate city-wide motor features\n",
    "    if motor_day.empty:\n",
    "        # Use the median of the specific year for city-wide calculations\n",
    "        year_median_vol = yearly_median_vol[yearly_median_vol['year'] == current_year]['Vol'].median()\n",
    "        city_total_motor_volume = year_median_vol * len(motor_gdf['SegmentID'].unique())\n",
    "        city_avg_motor_volume = year_median_vol\n",
    "    else:\n",
    "        city_total_motor_volume = motor_day['Vol'].sum()\n",
    "        city_avg_motor_volume = motor_day['Vol'].mean()\n",
    "\n",
    "    # Loop through each bike station on that date\n",
    "    for idx, bike_row in bike_day.iterrows():\n",
    "        station_name = bike_row['name']\n",
    "        nearby_segments = station_matches.get(station_name, [])\n",
    "\n",
    "        # Filter motor data for the matched segments on the current date\n",
    "        nearby_motor = motor_day[motor_day['SegmentID'].isin(nearby_segments)]\n",
    "\n",
    "        # If no data for the date, use the median of that year for the specific segments\n",
    "        if nearby_motor.empty:\n",
    "            # Filter median for specific year and segments\n",
    "            year_median_vol_segment = yearly_median_vol[\n",
    "                (yearly_median_vol['SegmentID'].isin(nearby_segments)) & \n",
    "                (yearly_median_vol['year'] == current_year)\n",
    "            ]['Vol'].median()\n",
    "            \n",
    "            # If the yearly median is also missing, use the global median as a fallback\n",
    "            if pd.isna(year_median_vol_segment):\n",
    "                year_median_vol_segment = motor_gdf['Vol'].median()\n",
    "\n",
    "            # Create a placeholder with the computed median\n",
    "            nearby_motor = pd.DataFrame([{\n",
    "                'Vol': year_median_vol_segment,\n",
    "                'SegmentID': ','.join(map(str, nearby_segments)),\n",
    "                'geometry': bike_row.geometry\n",
    "            }])\n",
    "\n",
    "        # Aggregate nearby motor features\n",
    "        results.append({\n",
    "            'date': current_date,\n",
    "            'station_name': bike_row['name'],\n",
    "            'latitude': bike_row['latitude'],\n",
    "            'longitude': bike_row['longitude'],\n",
    "            'cycling_volume': bike_row['counts'],\n",
    "\n",
    "            # Local (6 km radius) features\n",
    "            'avg_motor_volume': nearby_motor['Vol'].mean(),\n",
    "            'total_motor_volume': nearby_motor['Vol'].sum(),\n",
    "            'num_motor_sources': len(nearby_motor),\n",
    "\n",
    "            # City-wide features\n",
    "            'city_avg_motor_volume': city_avg_motor_volume,\n",
    "            'city_total_motor_volume': city_total_motor_volume\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63387a11-e72c-460a-8ecd-5a17b2d4a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36461 entries, 0 to 36460\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   date                     36461 non-null  object \n",
      " 1   station_name             36461 non-null  object \n",
      " 2   latitude                 36461 non-null  float64\n",
      " 3   longitude                36461 non-null  float64\n",
      " 4   cycling_volume           36461 non-null  int64  \n",
      " 5   avg_motor_volume         36461 non-null  float64\n",
      " 6   total_motor_volume       36461 non-null  float64\n",
      " 7   num_motor_sources        36461 non-null  int64  \n",
      " 8   city_avg_motor_volume    36461 non-null  float64\n",
      " 9   city_total_motor_volume  36461 non-null  float64\n",
      "dtypes: float64(6), int64(2), object(2)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrame and save\n",
    "final_df = pd.DataFrame(results)\n",
    "\n",
    "# And, check the final_df\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498b3bb2-4520-4c90-95ca-e3f7e4efd783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cycling_volume</th>\n",
       "      <th>avg_motor_volume</th>\n",
       "      <th>total_motor_volume</th>\n",
       "      <th>num_motor_sources</th>\n",
       "      <th>city_avg_motor_volume</th>\n",
       "      <th>city_total_motor_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>111th St at 50th Ave</td>\n",
       "      <td>40.745630</td>\n",
       "      <td>-73.852500</td>\n",
       "      <td>120</td>\n",
       "      <td>17832.0</td>\n",
       "      <td>17832.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15862.333333</td>\n",
       "      <td>47587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>Amsterdam Ave at 86th St.</td>\n",
       "      <td>40.787700</td>\n",
       "      <td>-73.975050</td>\n",
       "      <td>2053</td>\n",
       "      <td>5728.0</td>\n",
       "      <td>5728.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15862.333333</td>\n",
       "      <td>47587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>Brooklyn Bridge Bicycle Path (Roadway)</td>\n",
       "      <td>40.712656</td>\n",
       "      <td>-74.004464</td>\n",
       "      <td>3590</td>\n",
       "      <td>56957.0</td>\n",
       "      <td>56957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15862.333333</td>\n",
       "      <td>47587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>Brooklyn Bridge Bike Path</td>\n",
       "      <td>40.709274</td>\n",
       "      <td>-74.000990</td>\n",
       "      <td>26</td>\n",
       "      <td>56957.0</td>\n",
       "      <td>56957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15862.333333</td>\n",
       "      <td>47587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>Columbus Ave at 86th St.</td>\n",
       "      <td>40.787700</td>\n",
       "      <td>-73.975050</td>\n",
       "      <td>1561</td>\n",
       "      <td>5728.0</td>\n",
       "      <td>5728.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15862.333333</td>\n",
       "      <td>47587.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                            station_name   latitude  longitude  \\\n",
       "0  2022-05-09                    111th St at 50th Ave  40.745630 -73.852500   \n",
       "1  2022-05-09               Amsterdam Ave at 86th St.  40.787700 -73.975050   \n",
       "2  2022-05-09  Brooklyn Bridge Bicycle Path (Roadway)  40.712656 -74.004464   \n",
       "3  2022-05-09               Brooklyn Bridge Bike Path  40.709274 -74.000990   \n",
       "4  2022-05-09                Columbus Ave at 86th St.  40.787700 -73.975050   \n",
       "\n",
       "   cycling_volume  avg_motor_volume  total_motor_volume  num_motor_sources  \\\n",
       "0             120           17832.0             17832.0                  1   \n",
       "1            2053            5728.0              5728.0                  1   \n",
       "2            3590           56957.0             56957.0                  1   \n",
       "3              26           56957.0             56957.0                  1   \n",
       "4            1561            5728.0              5728.0                  1   \n",
       "\n",
       "   city_avg_motor_volume  city_total_motor_volume  \n",
       "0           15862.333333                  47587.0  \n",
       "1           15862.333333                  47587.0  \n",
       "2           15862.333333                  47587.0  \n",
       "3           15862.333333                  47587.0  \n",
       "4           15862.333333                  47587.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7fb11e-698c-4f75-b5a9-bff093c6797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved as 'bike_with_motor_traffic_nyc.csv'\n"
     ]
    }
   ],
   "source": [
    "final_df.to_csv('bike_with_motor_traffic_nyc.csv', index=False)\n",
    "\n",
    "print(\"Merged data saved as 'bike_with_motor_traffic_nyc.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37bf8897-71f2-40e8-a398-ac8e178184e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           latitude     longitude  cycling_volume  avg_motor_volume  \\\n",
      "count  36461.000000  36461.000000    36461.000000      36461.000000   \n",
      "mean      40.721497    -73.973061     2151.641699      11171.669462   \n",
      "std        0.047611      0.045053     2048.057501      13041.986564   \n",
      "min       40.584100    -74.072075        0.000000          0.000000   \n",
      "25%       40.709274    -73.994950      372.000000       5728.000000   \n",
      "50%       40.714573    -73.971382     1725.000000       5917.000000   \n",
      "75%       40.751010    -73.951492     3146.000000      13459.500000   \n",
      "max       40.857669    -73.852500    13346.000000     154879.000000   \n",
      "\n",
      "       total_motor_volume  num_motor_sources  city_avg_motor_volume  \\\n",
      "count        36461.000000       36461.000000           36461.000000   \n",
      "mean         11302.867276           1.014838           10784.006405   \n",
      "std          13306.458627           0.169780            9346.416826   \n",
      "min              0.000000           1.000000               0.000000   \n",
      "25%           5728.000000           1.000000            6099.000000   \n",
      "50%           5917.000000           1.000000            8827.000000   \n",
      "75%          13459.500000           1.000000           11583.000000   \n",
      "max         198247.000000          10.000000           74195.500000   \n",
      "\n",
      "       city_total_motor_volume  \n",
      "count             3.646100e+04  \n",
      "mean              9.958516e+06  \n",
      "std               1.350933e+07  \n",
      "min               0.000000e+00  \n",
      "25%               2.292500e+04  \n",
      "50%               5.340600e+04  \n",
      "75%               2.615352e+07  \n",
      "max               3.505493e+07  \n",
      "Number of unique dates: 3653\n",
      "Number of unique stations: 19\n"
     ]
    }
   ],
   "source": [
    "print(final_df.describe())\n",
    "print(\"Number of unique dates:\", final_df['date'].nunique())\n",
    "print(\"Number of unique stations:\", final_df['station_name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238fc993-5335-4ea8-b5cf-90422df13619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
